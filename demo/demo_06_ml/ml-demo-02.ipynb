{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Azure ML workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "workspace_name = 'sd-ml'\r\n",
        "subscription_id = 'c374c749-c070-4b3b-9fb4-40a657b1d4a5' # subscription id of ADLS account\r\n",
        "resource_group = 'rs-sd-learn-sth-new' # resource group of ADLS account\r\n",
        "\r\n",
        "workspace = Workspace.get(\r\n",
        "    name = workspace_name,\r\n",
        "    subscription_id = subscription_id,\r\n",
        "    resource_group = resource_group\r\n",
        ")\r\n",
        "\r\n",
        "print (\"workspace to be used: \" + workspace.name)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "workspace to be used: sd-ml\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620333470915
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get or set up datastore"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "datastore_name = 'learnsthnew_datastore'\r\n",
        "filesystem = 'learnsthnew'\r\n",
        "\r\n",
        "subscription_id = 'c374c749-c070-4b3b-9fb4-40a657b1d4a5' # subscription id of ADLS account\r\n",
        "resource_group = 'rs-sd-learn-sth-new' # resource group of ADLS account\r\n",
        "\r\n",
        "account_name = 'sdsalearnsthnew' # ADLS Gen2 account name\r\n",
        "tenant_id = '680b5d20-b41e-46f8-a077-f482d0c64dbb' # tenant id of service principal\r\n",
        "client_id = '6df9c689-4854-45ec-a9c2-55194c54c511' # client id of service principal\r\n",
        "client_secret = 'Is5A5Jctw1~Ge-hi4EOS_RmRahG5_s43F4' # the secret of service principal\r\n",
        "\r\n",
        "try:\r\n",
        "    datastore = Datastore.get(\r\n",
        "        workspace = workspace,\r\n",
        "        datastore_name = datastore_name\r\n",
        "    )\r\n",
        "except Exception as exc:\r\n",
        "    datastore = Datastore.register_azure_data_lake_gen2(\r\n",
        "        workspace = workspace,\r\n",
        "        subscription_id = subscription_id,\r\n",
        "        resource_group = resource_group,\r\n",
        "        datastore_name = datastore_name,\r\n",
        "        account_name = account_name, # ADLS Gen2 account name\r\n",
        "        filesystem = filesystem, # ADLS Gen2 filesystem\r\n",
        "        tenant_id = tenant_id, # tenant id of service principal\r\n",
        "        client_id = client_id, # client id of service principal\r\n",
        "        client_secret = client_secret # the secret of service principal\r\n",
        "    )\r\n",
        "\r\n",
        "print (\"datastore to be used: \" + datastore.name)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datastore to be used: learnsthnew_datastore\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333472338
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get or set up dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "datastore_name = 'learnsthnew_datastore'\r\n",
        "dataset_name = 'playlist_statistics'\r\n",
        "dataset_description = 'radio song playlist statistics'\r\n",
        "\r\n",
        "try:\r\n",
        "    dataset = Dataset.get_by_name(\r\n",
        "        workspace = workspace, \r\n",
        "        name = dataset_name\r\n",
        "    )\r\n",
        "except Exception as exc:\r\n",
        "    datastore_paths = [(datastore, '/analytics/playlist_statistics.parquet/*.parquet')]\r\n",
        "    dataset = Dataset.Tabular.from_parquet_files(path=datastore_paths, validate=False)\r\n",
        "    dataset = dataset.register(\r\n",
        "        workspace=workspace,\r\n",
        "        name = dataset_name,\r\n",
        "        description = dataset_description\r\n",
        "    )\r\n",
        "\r\n",
        "print (\"dataset to be used: \" + dataset.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset to be used: playlist_statistics\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333475314
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data and convert dataset to pandas dataframe"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333494649
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check sample 5 rows of current dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "  radio_name month_name               artist_and_title  played\n0      RMFFM    January      #razemrobimydobro - Razem       0\n1      RMFFM    January  2+1 - Chodź Pomaluj Mój Świat       0\n2      RMFFM    January               Abba - Mamma Mia       1\n3      RMFFM    January         Abc - The Look Of Love       0\n4      RMFFM    January          Ac/dc - Thunderstruck       0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radio_name</th>\n      <th>month_name</th>\n      <th>artist_and_title</th>\n      <th>played</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RMFFM</td>\n      <td>January</td>\n      <td>#razemrobimydobro - Razem</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RMFFM</td>\n      <td>January</td>\n      <td>2+1 - Chodź Pomaluj Mój Świat</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RMFFM</td>\n      <td>January</td>\n      <td>Abba - Mamma Mia</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RMFFM</td>\n      <td>January</td>\n      <td>Abc - The Look Of Love</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RMFFM</td>\n      <td>January</td>\n      <td>Ac/dc - Thunderstruck</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333494822
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset into features and labels\r\n",
        "\r\n",
        "Features - attributes that will be used to predict the target value, please note that here we are using the encoded attributes and not the original ones\r\n",
        "\r\n",
        "Label - the label of each row, also the value that will be predicted"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\r\n",
        "features = [\"radio_name\", \"month_name\", \"artist_and_title\"]\r\n",
        "label = 'played'\r\n",
        "X, y = df[features].values, df[label].values"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333495198
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset into train and test subsets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# Split data 70%-30% into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cases: 19237748\n",
            "Test cases: 8244750\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620333501814
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create prediction model using pipeline, LogisticRegression and validate the model\r\n",
        "\r\n",
        "* **Pipeline** - pipeline in that case will allow us to encode the categorical features during the preprocessing phase, than we will be able to provide raw data to the model and the encoding will be handled in the model itself\r\n",
        "* **Accuracy classification score** - In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\r\n",
        "* **Other metrics** - Precision, Recall, F1-Score, Support, etc, please read more in that area\r\n",
        "* **Confusion matrix** - Compute confusion matrix to evaluate the accuracy of a classification.\r\n",
        "![alt text](img/confusion_matrix.png)\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ordinal that is used here is still no the best choice, but should be good enough in that case\r\n",
        "# for more see: https://www.kaggle.com/discdiver/category-encoders-examples (as an example)\r\n",
        "\r\n",
        "# Train the model\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Define preprocessing for categorical features (encode the Age column)\r\n",
        "categorical_features = [0,1]\r\n",
        "categorical_transformer = Pipeline(steps=[\r\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\r\n",
        "\r\n",
        "categorical_features_song = [2]\r\n",
        "categorical_transformer_song = Pipeline(steps=[\r\n",
        "    ('labelenc', OrdinalEncoder())])\r\n",
        "\r\n",
        "# Combine preprocessing steps\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('cat', categorical_transformer, categorical_features),\r\n",
        "        ('catsong', categorical_transformer_song, categorical_features_song)\r\n",
        "    ])\r\n",
        "\r\n",
        "# Create preprocessing and training pipeline\r\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
        "                           ('logregressor', DecisionTreeClassifier())])\r\n",
        "\r\n",
        "\r\n",
        "# fit the pipeline to train a logistic regression model on the training set\r\n",
        "model = pipeline.fit(X_train, (y_train))\r\n",
        "\r\n",
        "predictions = model.predict(X_test)\r\n",
        "print('Accuracy: ', accuracy_score(y_test, predictions))\r\n",
        "print(confusion_matrix(y_test, predictions))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9571007004457383\n",
            "[[7884085    5635]\n",
            " [ 348059    6971]]\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620335147791
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the model to check (predict) if given song will be played"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_a = model.predict([[\"RMFFM\",\"June\",\"Rotary - Na Jednej Z Dzikich Plaż\"]])\r\n",
        "predict_b = model.predict([[\"RMFFM\",\"December\",\"Rotary - Na Jednej Z Dzikich Plaż\"]])\r\n",
        "predict_c = model.predict([[\"RMFFM\",\"June\",\"Wham! - Last Christmas\"]])\r\n",
        "predict_d = model.predict([[\"RMFFM\",\"December\",\"Wham! - Last Christmas\"]])\r\n",
        "\r\n",
        "print (f\"Predict results using model 'a' for radio: RMFFM, month: June, artist and title: Rotary - Na Jednej Z Dzikich Plaż, results {str(predict_a[0])}\" )\r\n",
        "print (f\"Predict results using model 'a' for radio: RMFFM, month: December, artist and title: Rotary - Na Jednej Z Dzikich Plaż, results {str(predict_b[0])}\" )\r\n",
        "print (f\"Predict results using model 'a' for radio: RMFFM, month: June, artist and title: Rotary - Wham! - Last Christmas, results {str(predict_c[0])}\" )\r\n",
        "print (f\"Predict results using model 'a' for radio: RMFFM, month: December, artist and title: Rotary - Wham! - Last Christmas, results {str(predict_d[0])}\" )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict results using model 'a' for radio: RMFFM, month: June, artist and title: Rotary - Na Jednej Z Dzikich Plaż, results 1\n",
            "Predict results using model 'a' for radio: RMFFM, month: December, artist and title: Rotary - Na Jednej Z Dzikich Plaż, results 0\n",
            "Predict results using model 'a' for radio: RMFFM, month: June, artist and title: Rotary - Wham! - Last Christmas, results 0\n",
            "Predict results using model 'a' for radio: RMFFM, month: December, artist and title: Rotary - Wham! - Last Christmas, results 1\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620335147886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}