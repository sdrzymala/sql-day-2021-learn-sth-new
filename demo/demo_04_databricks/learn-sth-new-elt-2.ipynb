{"cells":[{"cell_type":"markdown","source":["#Notebook Description\n**Author**: Slawomir Drzymala\n\n**Description:**   \nThis notebook is getting the data from the curated layer of the data lake and preparing a dataset that can be used in further analysis placing them in the enriched layer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dcafaa9-46fd-45f4-b89b-bbbdc758fc72"}}},{"cell_type":"markdown","source":["#Set up connection to data lake on Azure\n\n**Things to be noticed:**   \n* **sensitive data alert** - please note that this is not recommended to store any key or any other sensitve data in the notebooks, this is just to make the code more simple for the demo. For real work please use Azure KeyVault or databricks secrets.\n* **multiple ways to connect to Azure data lake** - there are multiple options to connect to the Azure data lake, we can use the access key or the service principal, we can also mount the storage account so the storage account will be visible in many notebooks, please see link below for mode details"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01fd3fc4-acae-4c37-991c-78319c5f50ec"}}},{"cell_type":"code","source":["#vide https://docs.databricks.com/_static/notebooks/data-import/azure-data-lake-store.html\n#vide https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/adls-gen2/azure-datalake-gen2-get-started\nspark.conf.set(\n  \"fs.azure.account.key.sdsalearnsthnew.dfs.core.windows.net\", \n  \"RJMELuc9ffZPf5D0gwcbxJp+hWTkQuW8lmWa1DRFSF59aDiatDsMJ6X/yC/dHZtB7kdGl3cJIrYry++6EnCb5g==\" \n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23f12b2d-6d46-40a1-9c5f-4360c2e393c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Read entire dataset from curated layer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55466f05-84b1-44b4-a60b-ad83fa7004c1"}}},{"cell_type":"code","source":["# read all files from all radio stations\nbase_path = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/curated-initial/\"\nfile_path = f\"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/curated-initial/radio_name=*/year=*/*.parquet\"\ndf_playlist = spark.read.option(\"basePath\", base_path) \\\n                        .option('encoding', 'UTF-8') \\\n                        .parquet(file_path, multiLine=True)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa83c2ba-ff9f-4a5f-ad54-92f1c9425d81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Display 5 sample rows\n\n**Things to be noticed:**   \n* **display** - display is the magic Databricks function that can be used for visualization of many different objects including spark or pandas dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fca83d77-398d-44fc-9712-c58e96b96f38"}}},{"cell_type":"code","source":["display(df_playlist.head(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"548c4cab-cb09-438e-b6f2-a81d4790d2f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2019-12-31T00:00:00.000+0000","Peja/slums Attack","Szacunek Ludzi Ulicy (Explicit)","Eska",2019],["2019-12-31T00:05:00.000+0000","Tymek/tede","Rainman (Explicit)","Eska",2019],["2019-12-31T00:08:00.000+0000","Taconafide","Metallica 808 (Explicit)","Eska",2019],["2019-12-31T00:12:00.000+0000","Nautilus","Blat","Eska",2019],["2019-12-31T00:16:00.000+0000","Young Multi","Jeden Dzien (Explicit)","Eska",2019]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"datetime","type":"\"timestamp\"","metadata":"{}"},{"name":"artist","type":"\"string\"","metadata":"{}"},{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"radio_name","type":"\"string\"","metadata":"{}"},{"name":"year","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>datetime</th><th>artist</th><th>title</th><th>radio_name</th><th>year</th></tr></thead><tbody><tr><td>2019-12-31T00:00:00.000+0000</td><td>Peja/slums Attack</td><td>Szacunek Ludzi Ulicy (Explicit)</td><td>Eska</td><td>2019</td></tr><tr><td>2019-12-31T00:05:00.000+0000</td><td>Tymek/tede</td><td>Rainman (Explicit)</td><td>Eska</td><td>2019</td></tr><tr><td>2019-12-31T00:08:00.000+0000</td><td>Taconafide</td><td>Metallica 808 (Explicit)</td><td>Eska</td><td>2019</td></tr><tr><td>2019-12-31T00:12:00.000+0000</td><td>Nautilus</td><td>Blat</td><td>Eska</td><td>2019</td></tr><tr><td>2019-12-31T00:16:00.000+0000</td><td>Young Multi</td><td>Jeden Dzien (Explicit)</td><td>Eska</td><td>2019</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Create playlist fact table\n\n**New dataframe**\n* **df_playlist_enriched** - copy of playlist dataframe with additional columns\n\n**New columns**\n* **artist_and_title** - concatenation of the artitist and the title - key for single song\n* **year** - year derived from the datetime time stamp of each row\n* **date** - date without a time derived from the time stamp\n* **month_name** - month derived from datetime time stamp of each row\n* **played** - static value, indicator that the song was played in the given time\n\n**Things to be noticed:**   \n* **display** - display is the magic Databricks function that can be used for visualization of many different objects including spark or pandas dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c3b5846-bfb1-462f-9017-7039e001ad92"}}},{"cell_type":"code","source":["from pyspark.sql.functions import input_file_name\nfrom pyspark.sql.functions import lit, split, reverse, regexp_replace, count, concat_ws, coalesce, desc, trim, lower\nfrom pyspark.sql.functions import year, date_format, hour, to_date, col\n\ndf_playlist_enriched = df_playlist.select(\"radio_name\", \"artist\", \"datetime\", \"title\") \\\n                                  .withColumn(\"artist_trim\", lower(trim(\"artist\"))) \\\n                                  .withColumn(\"title_trim\", lower(trim(\"title\"))) \\\n                                  .withColumn(\"artist_and_title\", concat_ws(\" - \", \"artist_trim\", \"title_trim\")) \\\n                                  .withColumn(\"date\", to_date(df_playlist[\"datetime\"])) \\\n                                  .withColumn(\"month_name\", date_format(\"date\", \"MMMM\")) \\\n                                  .withColumn(\"year\", year(to_date(\"date\"))) \\\n                                  .withColumn(\"played\", lit(1)) \\\n                                  .select(\"radio_name\", \\\n                                          col(\"artist_trim\").alias(\"artist\"), \\\n                                          \"datetime\", \\\n                                          col(\"title_trim\").alias(\"title\"), \\\n                                          \"artist_and_title\", \\\n                                          \"date\", \\\n                                          \"year\", \\\n                                          \"month_name\", \\\n                                          \"played\" \\\n                                   )\n\noutput_directory = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/playlist/\"\ndf_playlist_enriched.write.mode('overwrite') \\\n                 .partitionBy(\"radio_name\", \"year\") \\\n                 .parquet(output_directory)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9330db6a-2e7b-4b8d-ad68-a4601d69dfea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Create song dimension, get unique songs\n\n**New dataframe**\n* **df_unique_songs** - dataframe with list of all unique songs from entire playlist dataframe\n* **df_songs** - dataframe with unique list of songs enriched with the attributes that will be used to keep information about the song from spotify"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"055837d9-6155-4187-bce7-4890d9055c10"}}},{"cell_type":"code","source":["from pyspark.sql.functions import input_file_name\nfrom pyspark.sql.functions import lit, split, reverse, regexp_replace, count, concat_ws, coalesce, desc\nfrom pyspark.sql.functions import year, date_format, hour, to_date, col\nfrom pyspark.sql.types import StringType, BooleanType\n\n# add basic attributes\ndf_unique_songs = df_playlist.select(df_playlist[\"artist\"], df_playlist[\"title\"]) \\\n                                     .withColumn(\"artist_trim\", lower(trim(\"artist\"))) \\\n                                     .withColumn(\"title_trim\", lower(trim(\"title\"))) \\\n                                     .groupby(\"artist_trim\", \"title_trim\") \\\n                                     .agg(count(lit(1)).alias(\"cnt\")) \\\n                                     .select(\"artist_trim\", \"title_trim\", \"cnt\") \\\n                                     .withColumn(\"artist_and_title\", concat_ws(\" - \", \"artist_trim\", \"title_trim\")) \\\n                                     .select(\"artist_and_title\", col(\"artist_trim\").alias(\"artist\"), col(\"title_trim\").alias(\"title\"), \"cnt\") \\\n                                     .orderBy(desc(\"cnt\"))\n\n# add spotify columns\ndf_songs = df_unique_songs.withColumn('track_id', lit('#').cast(StringType())) \\\n                          .withColumn('track_href', lit('#').cast(StringType())) \\\n                          .withColumn('track_is_local', lit('#').cast(StringType())) \\\n                          .withColumn('track_is_playable', lit('#').cast(StringType())) \\\n                          .withColumn('track_name', lit('#').cast(StringType())) \\\n                          .withColumn('track_popularity', lit('#').cast(StringType())) \\\n                          .withColumn('track_track_number', lit('#').cast(StringType())) \\\n                          .withColumn('track_type', lit('#').cast(StringType())) \\\n                          .withColumn('track_uri', lit('#').cast(StringType())) \\\n                          .withColumn('track_duration_ms', lit('#').cast(StringType())) \\\n                          .withColumn('track_disc_number', lit('#').cast(StringType())) \\\n                          .withColumn('track_explicit', lit('#').cast(StringType())) \\\n                          .withColumn('track_external_ids_isrc', lit('#').cast(StringType())) \\\n                          .withColumn('album_album_type', lit('#').cast(StringType())) \\\n                          .withColumn('album_href', lit('#').cast(StringType())) \\\n                          .withColumn('album_id', lit('#').cast(StringType())) \\\n                          .withColumn('album_name', lit('#').cast(StringType())) \\\n                          .withColumn('album_release_date', lit('#').cast(StringType())) \\\n                          .withColumn('album_release_date_precision', lit('#').cast(StringType())) \\\n                          .withColumn('album_total_tracks', lit('#').cast(StringType())) \\\n                          .withColumn('album_type', lit('#').cast(StringType())) \\\n                          .withColumn('album_uri', lit('#').cast(StringType())) \\\n                          .withColumn('album_album_type', lit('#').cast(StringType())) \\\n                          .withColumn('is_track_downloaded', lit(0).cast(BooleanType())) \\\n                          .withColumn('audio_features_danceability', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_energy', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_key', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_loudness', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_mode', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_speechiness', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_acousticness', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_instrumentalness', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_liveness', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_valence', lit('#').cast(StringType())) \\\n                          .withColumn('audio_features_tempo', lit('#').cast(StringType())) \\\n                          .withColumn('is_audio_features_downloaded', lit(0).cast(BooleanType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6fd5aed-be8c-475d-ab78-8a5fdb2b4a95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Display 5 sample rows\n\n**Things to be noticed:**   \n* **display** - display is the magic Databricks function that can be used for visualization of many different objects including spark or pandas dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41b124ee-f193-4827-b9bd-f84b60278d95"}}},{"cell_type":"code","source":["display(df_songs.head(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01df9711-fdec-4a34-9a33-20d202b6d8f6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["antyradio - najlepszy rock na świecie","antyradio","najlepszy rock na świecie",18546,"#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#",false,"#","#","#","#","#","#","#","#","#","#","#",false],["c - bool","c","bool",9290,"#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#",false,"#","#","#","#","#","#","#","#","#","#","#",false],["ewa farna - ewakuacja","ewa farna","ewakuacja",4568,"#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#",false,"#","#","#","#","#","#","#","#","#","#","#",false],["melanie fiona - monday morning","melanie fiona","monday morning",4545,"#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#",false,"#","#","#","#","#","#","#","#","#","#","#",false],["t.love - warszawa","t.love","warszawa",4383,"#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#","#",false,"#","#","#","#","#","#","#","#","#","#","#",false]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"artist_and_title","type":"\"string\"","metadata":"{}"},{"name":"artist","type":"\"string\"","metadata":"{}"},{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"cnt","type":"\"long\"","metadata":"{}"},{"name":"track_id","type":"\"string\"","metadata":"{}"},{"name":"track_href","type":"\"string\"","metadata":"{}"},{"name":"track_is_local","type":"\"string\"","metadata":"{}"},{"name":"track_is_playable","type":"\"string\"","metadata":"{}"},{"name":"track_name","type":"\"string\"","metadata":"{}"},{"name":"track_popularity","type":"\"string\"","metadata":"{}"},{"name":"track_track_number","type":"\"string\"","metadata":"{}"},{"name":"track_type","type":"\"string\"","metadata":"{}"},{"name":"track_uri","type":"\"string\"","metadata":"{}"},{"name":"track_duration_ms","type":"\"string\"","metadata":"{}"},{"name":"track_disc_number","type":"\"string\"","metadata":"{}"},{"name":"track_explicit","type":"\"string\"","metadata":"{}"},{"name":"track_external_ids_isrc","type":"\"string\"","metadata":"{}"},{"name":"album_album_type","type":"\"string\"","metadata":"{}"},{"name":"album_href","type":"\"string\"","metadata":"{}"},{"name":"album_id","type":"\"string\"","metadata":"{}"},{"name":"album_name","type":"\"string\"","metadata":"{}"},{"name":"album_release_date","type":"\"string\"","metadata":"{}"},{"name":"album_release_date_precision","type":"\"string\"","metadata":"{}"},{"name":"album_total_tracks","type":"\"string\"","metadata":"{}"},{"name":"album_type","type":"\"string\"","metadata":"{}"},{"name":"album_uri","type":"\"string\"","metadata":"{}"},{"name":"is_track_downloaded","type":"\"boolean\"","metadata":"{}"},{"name":"audio_features_danceability","type":"\"string\"","metadata":"{}"},{"name":"audio_features_energy","type":"\"string\"","metadata":"{}"},{"name":"audio_features_key","type":"\"string\"","metadata":"{}"},{"name":"audio_features_loudness","type":"\"string\"","metadata":"{}"},{"name":"audio_features_mode","type":"\"string\"","metadata":"{}"},{"name":"audio_features_speechiness","type":"\"string\"","metadata":"{}"},{"name":"audio_features_acousticness","type":"\"string\"","metadata":"{}"},{"name":"audio_features_instrumentalness","type":"\"string\"","metadata":"{}"},{"name":"audio_features_liveness","type":"\"string\"","metadata":"{}"},{"name":"audio_features_valence","type":"\"string\"","metadata":"{}"},{"name":"audio_features_tempo","type":"\"string\"","metadata":"{}"},{"name":"is_audio_features_downloaded","type":"\"boolean\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>artist_and_title</th><th>artist</th><th>title</th><th>cnt</th><th>track_id</th><th>track_href</th><th>track_is_local</th><th>track_is_playable</th><th>track_name</th><th>track_popularity</th><th>track_track_number</th><th>track_type</th><th>track_uri</th><th>track_duration_ms</th><th>track_disc_number</th><th>track_explicit</th><th>track_external_ids_isrc</th><th>album_album_type</th><th>album_href</th><th>album_id</th><th>album_name</th><th>album_release_date</th><th>album_release_date_precision</th><th>album_total_tracks</th><th>album_type</th><th>album_uri</th><th>is_track_downloaded</th><th>audio_features_danceability</th><th>audio_features_energy</th><th>audio_features_key</th><th>audio_features_loudness</th><th>audio_features_mode</th><th>audio_features_speechiness</th><th>audio_features_acousticness</th><th>audio_features_instrumentalness</th><th>audio_features_liveness</th><th>audio_features_valence</th><th>audio_features_tempo</th><th>is_audio_features_downloaded</th></tr></thead><tbody><tr><td>antyradio - najlepszy rock na świecie</td><td>antyradio</td><td>najlepszy rock na świecie</td><td>18546</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td></tr><tr><td>c - bool</td><td>c</td><td>bool</td><td>9290</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td></tr><tr><td>ewa farna - ewakuacja</td><td>ewa farna</td><td>ewakuacja</td><td>4568</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td></tr><tr><td>melanie fiona - monday morning</td><td>melanie fiona</td><td>monday morning</td><td>4545</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td></tr><tr><td>t.love - warszawa</td><td>t.love</td><td>warszawa</td><td>4383</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>#</td><td>false</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Save song dataframe as delta\n\n**Things to be noticed:**\n* **idea** - we are going to fill the empty columns in the next stages from the information from spotify API to have the possibility to easily and efficiently update the data in the data lake we are going to use a \"delta lake\" functionality\n* **delta lake** - is an open source storage layer that brings reliability to data lakes. Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing. Delta Lake runs on top of your existing data lake and is fully compatible with Apache Spark APIs. Delta Lake on Databricks allows you to configure Delta Lake based on your workload patterns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3540a74-45db-4bb2-8870-ebb5f42ddcab"}}},{"cell_type":"code","source":["output_file = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet\"\ndf_songs.write.format(\"delta\").save(output_file)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"208fe44d-652e-4d82-8b73-abbb787adf01"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Create functions to retrive data from Spotify API\n\n**Things to be noticed:**\n* **python** - please note that we can easilty write a custom code inside the notebook and later on use those functions together with the dataframes\n* **python function vs udf** - please note that here we are creating a functions that will be executed row by row, that's primarly because of the need to execute the external api, please also note that in Databricks we can also create a custom functions (udf) that we can execute on the column level and get the most out of the spark engine"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2103d4f-2e85-4e6f-aeaf-61db870042b9"}}},{"cell_type":"code","source":["import requests\nimport urllib\n\n# custom exception template\nclass MyException(Exception):\n    pass\n\n# function to get the spotify access token to be able to make the API call\ndef get_header_with_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET):\n  \n  auth_response = requests.post(AUTH_URL, {\n    'grant_type': 'client_credentials',\n    'client_id': CLIENT_ID,\n    'client_secret': CLIENT_SECRET,\n  })\n\n  # convert the response to JSON\n  auth_response_data = auth_response.json()\n\n  # save the access token\n  access_token = auth_response_data['access_token']\n\n  # specify request header\n  headers = {\n      'Authorization': 'Bearer {token}'.format(token=access_token)\n  }\n  \n  return headers\n  \n# function to search for a song in spotify API and among the other basic info get the track ID\ndef get_spotify_track(AUTH_URL, CLIENT_ID, CLIENT_SECRET, BASE_URL, track_artist, track_name):\n  \n  headers = get_header_with_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET)\n  \n  q = f'artist:{urllib.parse.quote(track_artist)}+track:{urllib.parse.quote(track_name)}&type=track&market=PL'\n  full_url = BASE_URL + f'search?query={q}'\n  #print (full_url)\n  \n  response = requests.get(full_url, headers=headers)\n  response_json = response.json()\n  \n  #print (response_json)\n  \n  if response.status_code != 200:\n    raise MyException(\"limit reached, try again later\")\n  elif response.status_code == 200 and int(response_json[\"tracks\"][\"total\"]) > 0:\n    # one track might exists in multiple albums, we will return first that has the highest popularity\n    track = response_json[\"tracks\"][\"items\"][0]\n    return track\n  else:\n    return None\n  \n# get the information about the song from spotify audio features API\ndef get_spotify_track_audio_features(AUTH_URL, CLIENT_ID, CLIENT_SECRET, BASE_URL, track_id):\n  \n  headers = get_header_with_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET)\n  url = BASE_URL + f'audio-features?ids={track_id}'\n  response = requests.get(url, headers=headers)\n  response_json = response.json()\n   \n  return response_json\n "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0668696d-8bdf-4867-8dd7-505be71050e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Use spotify API to indentify each song and get basic info\n\n**Things to be noticed:**\n* **collect()** - action function is used to retrieve all elements from the dataset\n* **dataframe_name.alias(\"source_table_alias\").merge** - perform merge operation on the delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0421e5b-3ec1-4ba5-9d73-25ca18423ada"}}},{"cell_type":"code","source":["from pyspark.sql.functions import input_file_name\nfrom pyspark.sql.functions import lit, split, reverse, regexp_replace, count, concat_ws, coalesce, desc\nfrom pyspark.sql.functions import year, date_format, hour, to_date, col\nfrom pyspark.sql.types import StringType, BooleanType\n\nimport time\nimport pandas as pd\nfrom delta.tables import *\nfrom numpy import random\n\n# read delta table\ninput_file = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet\"\nsongs_delta_table = DeltaTable.forPath(spark, input_file)\n\n# get title and aritst name if the song wasn't already downloaded\n# also convert to spark dataframe and collect the results\nsongs_to_be_donlowaded = songs_delta_table.toDF()\n                                          .where(((col('is_track_downloaded') == 0) & (col('artist_and_title').like(\"%'%\") == False)))\n                                          .select(\"artist_and_title\", \"artist\", \"title\")\n                                          .orderBy(desc(\"cnt\"))\n                                          .collect()\n\n# spotify API secrets, please note that this should be taken from Databricks secrets\nBASE_URL = 'https://api.spotify.com/v1/'\nAUTH_URL = 'https://accounts.spotify.com/api/token'\nCLIENT_ID = '88a4f7cc9a9940b19f468fca7bd0a0a8'\nCLIENT_SECRET = '75168639ec5c4c869df3817a93c15cd9'\n\n# iterate through each song and call the spotify API to get the song info\n# if the temporary list of the enriched song list will reach 50 then save the results to the data lake\n# for saving use the artist and title as a key and perform a merge operation\ntracks = []\nfor song in songs_to_be_donlowaded:\n  try:\n    \n    # sleep a random number of seconds to avoid flooding the api\n    time.sleep(random.uniform(3, 15))\n    \n    # get the results from the API\n    track = get_spotify_track(AUTH_URL, CLIENT_ID, CLIENT_SECRET, BASE_URL, song[\"artist\"], song[\"title\"])\n      \n    # it might be that the song won't be found in spotify API so at this stage we will simply ignore\n    if track != None:\n    \n      # if API results is not empty than add the song to the table\n      tracks.append(\n        { \n            'artist_and_title': song[\"artist_and_title\"],\n            'album_album_type': track[\"album\"][\"album_type\"],\n            'album_href': track[\"album\"][\"href\"],\n            'album_id': track[\"album\"][\"id\"],\n            'album_name': track[\"album\"][\"name\"],\n            'album_release_date': track[\"album\"][\"release_date\"],\n            'album_release_date_precision': track[\"album\"][\"release_date_precision\"],\n            'album_total_tracks': track[\"album\"][\"total_tracks\"],\n            'album_type': track[\"album\"][\"type\"],\n            'album_uri': track[\"album\"][\"uri\"],\n            'track_disc_number': track[\"disc_number\"],\n            'track_duration_ms': track[\"duration_ms\"],\n            'track_explicit': track[\"explicit\"],\n            'track_external_ids_isrc': track[\"external_ids\"][\"isrc\"],\n            'track_href': track[\"href\"],\n            'track_id': track[\"id\"],\n            'track_is_local': track[\"is_local\"],\n            'track_is_playable': track[\"is_playable\"],\n            'track_name': track[\"name\"],\n            'track_popularity': track[\"popularity\"],\n            'track_track_number': track[\"track_number\"],\n            'track_type': track[\"type\"],\n            'track_uri': track[\"uri\"]\n         } \n      )\n      \n      # reports success of getting a single song\n      print (\"ok : \" + song[\"artist_and_title\"])\n\n      # if there is X number of songs in the temp list than save to the delta lake\n      if len(tracks) > 50:\n          \n          # reports saving to the data lake\n          print (\"start saving\")\n          \n          # conver the temp list of songs to the pandas dataframe and than create a spark dataframe\n          df_pd_tracks_to_save = pd.DataFrame(tracks)\n          df_tracks_to_save=spark.createDataFrame(df_pd_tracks_to_save) \n\n          # perform a merge operation on the data lake\n          songs_delta_table.alias(\"songs\").merge(\n              df_tracks_to_save.alias(\"updates\"),\n              \"songs.artist_and_title = updates.artist_and_title\") \\\n            .whenMatchedUpdate(set = \n                               { \n                                            'album_album_type': 'updates.album_album_type',\n                                            'album_href': 'updates.album_href',\n                                            'album_id': 'updates.album_id',\n                                            'album_name': 'updates.album_name',\n                                            'album_release_date': 'updates.album_release_date',\n                                            'album_release_date_precision': 'updates.album_release_date_precision',\n                                            'album_total_tracks': 'updates.album_total_tracks',\n                                            'album_type': 'updates.album_type',\n                                            'album_uri': 'updates.album_uri',\n                                            'track_disc_number': 'updates.track_disc_number',\n                                            'track_duration_ms': 'updates.track_duration_ms',\n                                            'track_explicit': 'updates.track_explicit',\n                                            'track_external_ids_isrc': 'updates.track_external_ids_isrc',\n                                            'track_href': 'updates.track_href',\n                                            'track_id': 'updates.track_id',\n                                            'track_is_local': 'updates.track_is_local',\n                                            'track_is_playable': 'updates.track_is_playable',\n                                            'track_name': 'updates.track_name',\n                                            'track_popularity': 'updates.track_popularity',\n                                            'track_track_number': 'updates.track_track_number',\n                                            'track_type': 'updates.track_type',\n                                            'track_uri': 'updates.track_uri',\n                                            'is_track_downloaded': '1',\n                                       } \n                              ) \\\n            .execute()\n\n          # report success of writing to the delta lake\n          print (\"finish saving, start clean up\")\n          \n          # clean up the temporary objects\n          tracks.clear()\n          del(df_pd_tracks_to_save)\n          del(df_tracks_to_save)\n          print (\"ok saved: \" + len(tracks))\n          \n    else:\n      # it might be that the song won't be find in the spotify api, mark the song anyhow\n      song_title_join = song['artist_and_title'].replace(\"'\", '')\n      songs_delta_table.update(f\"artist_and_title = '{song_title_join}'\", \n                               { \n                                    'is_track_downloaded': lit(1),\n                               } \n                              )\n      print (\"empty results for : \" + song[\"artist_and_title\"])\n      \n  except TypeError:\n      # it might be that the song won't be find in the spotify api, mark the song anyhow\n      song_title_join = song['artist_and_title'].replace(\"'\", '')\n      songs_delta_table.update(f\"artist_and_title = '{song_title_join}'\", \n                               { \n                                    'is_track_downloaded': lit(1),\n                               } \n                              )\n      print (\"ok but empty: \" + song[\"artist_and_title\"])\n  except Exception as e:\n      # if there is any other error than raise the exception\n      print (\"error: \" + song[\"artist_and_title\"])\n      raise\n\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef5e5b2f-91ca-4bfa-bfb0-8b8368e6bf4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">empty results for : Selena Gomez Feat. Marshmello - Wolves\nempty results for : Nosowska / Igo / Organek / Zalewski - Sobie I Wam\nempty results for : Taylor Swift - Love Story (Disco Lines Remix)\nempty results for : Ofenbach / Benjamin Ingrosso - Paradise\nempty results for : Monika Brodka - Miałeś Być...\nempty results for : Emigranci - Na Falochronie\nempty results for : Taylor Swift / Brendon Urie - Me!\nempty results for : Katarzyna Nosowska - Nim Stanie Się Tak\nempty results for : Clean Bandit / Zara Larsson - Symphony\nempty results for : Lost Frequencies / Zonderling / Kelvin Jones - Love To Go\nempty results for : David Guetta / Usher - Without You\nempty results for : Sean Paul / Dua Lipa - No Lie\nempty results for : Robin Schulz / James Blunt - Ok\nempty results for : Nelly Furtado - Give It To Me\nempty results for : Alle Farben / Janieck - Little Hollywood\nempty results for : Sting / Cheb Mami - Desert Rose\nempty results for : Muniek Staszczyk - Święty\nempty results for : Younotus / Janieck / Senex - Narcotic\nempty results for : Varius Manx - Pocałuj Noc (Do Ciebie)\nempty results for : Clean Bandit / Sean Paul / Anne - Marie\nempty results for : Wham! - Careless Whisper\nempty results for : Maciej Maleńczuk / Yugopolis - Ostatnia Nocka\nempty results for : The Weeknd / Daft Punk - I Feel It Coming\nempty results for : Bracia - Dlaczego\nempty results for : Daab - Ogrodu Serce (W Moim Ogrodzie)\nempty results for : Ameerah - The Sound Of Missing You\nempty results for : Tinchy Stryder - Number 1 (Feat. N\nempty results for : Maggie Reilly - Everytime We Touch (Ft. Mike Oldfield)\nempty results for : Madonna - The Power Of Goodbye\nempty results for : Enej - Radio Hello (Radio Edit)\nempty results for : Muniek Staszczyk - Tina\nempty results for : O.n.a - Kola Czasu\nempty results for : Wilki - Wolność Jak Marzenie\nempty results for : Michał Szyc - Noc I Dzień\nempty results for : Luis Fonsi / Daddy Yankee - Despacito\nempty results for : Dog Eat Dog - Expect The Unexpected\nempty results for : Jay - Z / Alicia Keys\nempty results for : Lost Frequencies / Zonderling - Crazy\nempty results for : Mezo / Kasia Wilk / Tabb - Sacrum\nempty results for : Micar - Brothers In Arms (Feat. Nico Santos)\nempty results for : Sia / Kendrick Lamar - The Greatest\nempty results for : Bednarek / Matheo - Talizman\nempty results for : Showtek/justin Prime - Cannoball\nempty results for : Vanotek / Eneli - Tell Me Who (Slider &amp; Magnit Remix)\nempty results for : Rihanna - Four Five Seconds\nempty results for : Matt Pokora - Oblivion\nempty results for : Goodwill / Hook N Sling - Take You Higher\nempty results for : Sigala / Ella Eyre - Came Here For Love\nempty results for : De Mono - Wszystko Jest Na Sprzedaż\nempty results for : Meduza / Becky Hill - Lose Control\nempty results for : Biały - Ta Chwila\nempty results for : Daria Zawiałow - Świt\nempty results for : Pitbull - Time Of Our Lives (Feat. Ne\nempty results for : 30 Seconds To Mars - Walk On Water\nempty results for : Paweł Kukiz - Bo Tutaj Jest Jak Jest (&amp; Jan Borysewicz)\nempty results for : Monika Brodka - Miałeś Być\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">empty results for : Selena Gomez Feat. Marshmello - Wolves\nempty results for : Nosowska / Igo / Organek / Zalewski - Sobie I Wam\nempty results for : Taylor Swift - Love Story (Disco Lines Remix)\nempty results for : Ofenbach / Benjamin Ingrosso - Paradise\nempty results for : Monika Brodka - Miałeś Być...\nempty results for : Emigranci - Na Falochronie\nempty results for : Taylor Swift / Brendon Urie - Me!\nempty results for : Katarzyna Nosowska - Nim Stanie Się Tak\nempty results for : Clean Bandit / Zara Larsson - Symphony\nempty results for : Lost Frequencies / Zonderling / Kelvin Jones - Love To Go\nempty results for : David Guetta / Usher - Without You\nempty results for : Sean Paul / Dua Lipa - No Lie\nempty results for : Robin Schulz / James Blunt - Ok\nempty results for : Nelly Furtado - Give It To Me\nempty results for : Alle Farben / Janieck - Little Hollywood\nempty results for : Sting / Cheb Mami - Desert Rose\nempty results for : Muniek Staszczyk - Święty\nempty results for : Younotus / Janieck / Senex - Narcotic\nempty results for : Varius Manx - Pocałuj Noc (Do Ciebie)\nempty results for : Clean Bandit / Sean Paul / Anne - Marie\nempty results for : Wham! - Careless Whisper\nempty results for : Maciej Maleńczuk / Yugopolis - Ostatnia Nocka\nempty results for : The Weeknd / Daft Punk - I Feel It Coming\nempty results for : Bracia - Dlaczego\nempty results for : Daab - Ogrodu Serce (W Moim Ogrodzie)\nempty results for : Ameerah - The Sound Of Missing You\nempty results for : Tinchy Stryder - Number 1 (Feat. N\nempty results for : Maggie Reilly - Everytime We Touch (Ft. Mike Oldfield)\nempty results for : Madonna - The Power Of Goodbye\nempty results for : Enej - Radio Hello (Radio Edit)\nempty results for : Muniek Staszczyk - Tina\nempty results for : O.n.a - Kola Czasu\nempty results for : Wilki - Wolność Jak Marzenie\nempty results for : Michał Szyc - Noc I Dzień\nempty results for : Luis Fonsi / Daddy Yankee - Despacito\nempty results for : Dog Eat Dog - Expect The Unexpected\nempty results for : Jay - Z / Alicia Keys\nempty results for : Lost Frequencies / Zonderling - Crazy\nempty results for : Mezo / Kasia Wilk / Tabb - Sacrum\nempty results for : Micar - Brothers In Arms (Feat. Nico Santos)\nempty results for : Sia / Kendrick Lamar - The Greatest\nempty results for : Bednarek / Matheo - Talizman\nempty results for : Showtek/justin Prime - Cannoball\nempty results for : Vanotek / Eneli - Tell Me Who (Slider &amp; Magnit Remix)\nempty results for : Rihanna - Four Five Seconds\nempty results for : Matt Pokora - Oblivion\nempty results for : Goodwill / Hook N Sling - Take You Higher\nempty results for : Sigala / Ella Eyre - Came Here For Love\nempty results for : De Mono - Wszystko Jest Na Sprzedaż\nempty results for : Meduza / Becky Hill - Lose Control\nempty results for : Biały - Ta Chwila\nempty results for : Daria Zawiałow - Świt\nempty results for : Pitbull - Time Of Our Lives (Feat. Ne\nempty results for : 30 Seconds To Mars - Walk On Water\nempty results for : Paweł Kukiz - Bo Tutaj Jest Jak Jest (&amp; Jan Borysewicz)\nempty results for : Monika Brodka - Miałeś Być\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Cancelled","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Use spotify API to get more information (audio features) about each song\n\n**Things to be noticed:**\n* **collect()** - action function is used to retrieve all elements from the dataset\n* **dataframe_name.alias(\"source_table_alias\").merge** - perform merge operation on the delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56f4e830-fdf9-427c-84b5-3b60b4944385"}}},{"cell_type":"code","source":["from pyspark.sql.functions import input_file_name\nfrom pyspark.sql.functions import lit, split, reverse, regexp_replace, count, concat_ws, coalesce, desc\nfrom pyspark.sql.functions import year, date_format, hour, to_date, col\nfrom pyspark.sql.types import StringType, BooleanType\n\nimport time\nimport pandas as pd\nfrom delta.tables import *\nfrom numpy import random\n\n# parameters\ninput_file = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet\"\nBASE_URL = 'https://api.spotify.com/v1/'\nAUTH_URL = 'https://accounts.spotify.com/api/token'\nCLIENT_ID = '88a4f7cc9a9940b19f468fca7bd0a0a8'\nCLIENT_SECRET = '75168639ec5c4c869df3817a93c15cd9'\n\n# iterate till all of the songs will be parsed\nwhile True:\n  \n  # read 100 songs from the delta lake that were not enriched yet\n  # there is a limit on spotify API and we can get information about only 100 songs at single APi call\n  songs_delta_table = DeltaTable.forPath(spark, input_file)\n  track_ids_to_be_downloaded = songs_delta_table.toDF() \\\n                                                .where(\"track_id != '#' and is_audio_features_downloaded == False\") \\\n                                                .select(\"track_id\") \\\n                                                .limit(100) \\\n                                                .distinct() \\\n                                                .collect()\n  \n  # if there is no more songs to be enriched than break the loop\n  if len(track_ids_to_be_downloaded) == 0:\n    break\n  \n  # convert list of the track IDs to the comma separated list\n  track_ids_list = \",\".join([track_id[\"track_id\"] for track_id in track_ids_to_be_downloaded])\n\n  # wait a random number of songs and then make a call to the API\n  # the call will get the informationa about 100 songs in single call\n  time.sleep(random.uniform(3, 15))\n  tracks_audio_features = get_spotify_track_audio_features(AUTH_URL, CLIENT_ID, CLIENT_SECRET, BASE_URL, track_ids_list)\n\n  # create a temp table that will hold the information about multiple songs\n  tracks = []\n  \n  # iterate through each song, get the information about each song and then add to the temp table\n  for track_audio_features in tracks_audio_features[\"audio_features\"]:\n    try:\n      tracks.append(\n          { \n            'track_id': track_audio_features[\"id\"],\n            'audio_features_danceability': track_audio_features[\"danceability\"],\n            'audio_features_energy': track_audio_features[\"energy\"],\n            'audio_features_key': track_audio_features[\"key\"],\n            'audio_features_loudness': track_audio_features[\"loudness\"],\n            'audio_features_mode': track_audio_features[\"mode\"],\n            'audio_features_speechiness': track_audio_features[\"speechiness\"],\n            'audio_features_acousticness': track_audio_features[\"acousticness\"],\n            'audio_features_instrumentalness': track_audio_features[\"instrumentalness\"],\n            'audio_features_liveness': track_audio_features[\"liveness\"],\n            'audio_features_valence': track_audio_features[\"valence\"],\n            'audio_features_tempo': track_audio_features[\"tempo\"],\n            'is_audio_features_downloaded': 1,\n           } \n      )\n    except:\n      pass\n    \n  # it might be that the spotify won't return the results from each song \n  # therefore we will check if the temp table is not empty\n  if len(tracks) > 0:\n    \n    # convert the temp list with enriched songs to the pandas dataframe and then to the spark dataframe\n    df_pd_tracks_to_save = pd.DataFrame(tracks)\n    df_tracks_to_save=spark.createDataFrame(df_pd_tracks_to_save) \n\n    # use merge to update the songs in the data lake\n    songs_delta_table.alias(\"songs\").merge(\n        df_tracks_to_save.alias(\"updates\"),\n        \"songs.track_id = updates.track_id\") \\\n      .whenMatchedUpdate(set = \n                         { \n                            'audio_features_danceability': 'updates.audio_features_danceability',\n                            'audio_features_energy': 'updates.audio_features_energy',\n                            'audio_features_key': 'updates.audio_features_key',\n                            'audio_features_loudness': 'updates.audio_features_loudness',\n                            'audio_features_mode': 'updates.audio_features_mode',\n                            'audio_features_speechiness': 'updates.audio_features_speechiness',\n                            'audio_features_acousticness': 'updates.audio_features_acousticness',\n                            'audio_features_instrumentalness': 'updates.audio_features_instrumentalness',\n                            'audio_features_liveness': 'updates.audio_features_liveness',\n                            'audio_features_valence': 'updates.audio_features_valence',\n                            'audio_features_tempo': 'updates.audio_features_tempo',\n                            'is_audio_features_downloaded': 'updates.is_audio_features_downloaded'\n                         } \n                      ) \\\n      .execute()\n\n    # report success and clean the temp variables\n    print (\"finish saving another tracks chunk, start clean up\")\n    tracks.clear()\n    del(df_pd_tracks_to_save)\n    del(df_tracks_to_save)\n  else:\n    break"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a68c6592-eb88-4197-b1cc-3270d6f1fb58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Cancelled","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Optimize the delta lake table (optional)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94e52c90-71ef-4884-abd6-17f4e7280c71"}}},{"cell_type":"code","source":["# read more about coalsesce vs repartition\n\ndisplay(spark.sql(\"DROP TABLE IF EXISTS songs\"))\n\ndisplay(spark.sql(\"CREATE TABLE songs USING DELTA LOCATION 'abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet'\"))\n\ndisplay(spark.sql(\"ALTER TABLE songs SET TBLPROPERTIES ( delta.targetFileSize = '100mb')\"))\n  \ndisplay(spark.sql(\"OPTIMIZE songs\"))\n\ndisplay(spark.sql(\"VACUUM songs\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6dcd1745-a1e9-40a7-925d-5bf431c24137"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#Show list of files in enriched layer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e0b3347-6052-4794-a284-b91340439577"}}},{"cell_type":"code","source":["# read all files from all radio stations\nfile_path = f\"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/\"\n\ndisplay(\n  dbutils.fs.ls(file_path)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7070e2bb-b4dd-420e-bb11-7f7e28afb502"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/playlist/","playlist/",0],["abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet/","songs.parquet/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/playlist/</td><td>playlist/</td><td>0</td></tr><tr><td>abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet/</td><td>songs.parquet/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e12e56cb-2fe1-40b4-a467-8421a66446c9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dda25d3a-30ef-4bf3-a055-286a795f9029"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7696a214-3808-4f40-9773-cf35d3c9df45"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d905b52-1f41-4c1d-a984-d32f19311e82"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26b4d734-bf1c-4ab6-8708-a4144a9818c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Reload from songs_copy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"771ab2e9-ad47-4426-aa3c-1ee441df939c"}}},{"cell_type":"code","source":["from delta.tables import *\noutput_file = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs.parquet\"\noutput_songs_delta_table = DeltaTable.forPath(spark, output_file)\n\nfrom delta.tables import *\ninput_file = \"abfss://learnsthnew@sdsalearnsthnew.dfs.core.windows.net/enriched/songs_copy.parquet\"\ninput_songs_delta_table = DeltaTable.forPath(spark, input_file)\ninput_songs = input_songs_delta_table.toDF() \\\n                                     .where(\"track_id != '#'\") \\\n                                     .withColumn(\"artist_trim\", lower(trim(\"artist\"))) \\\n                                     .withColumn(\"title_trim\", lower(trim(\"title\"))) \\\n                                     .withColumn(\"artist_and_title\", concat_ws(\" - \", \"artist_trim\", \"title_trim\")) \\\n                                     .select(\n                                        'artist_and_title',\n                                        'track_id',\n                                        'track_href',\n                                        'track_is_local',\n                                        'track_is_playable',\n                                        'track_name',\n                                        'track_popularity',\n                                        'track_track_number',\n                                        'track_type',\n                                        'track_uri',\n                                        'track_duration_ms',\n                                        'track_disc_number',\n                                        'track_explicit',\n                                        'track_external_ids_isrc',\n                                        'album_album_type',\n                                        'album_href',\n                                        'album_id',\n                                        'album_name',\n                                        'album_release_date',\n                                        'album_release_date_precision',\n                                        'album_total_tracks',\n                                        'album_type',\n                                        'album_uri',\n                                        'album_album_type',\n                                        'audio_features_danceability',\n                                        'audio_features_energy',\n                                        'audio_features_key',\n                                        'audio_features_loudness',\n                                        'audio_features_mode',\n                                        'audio_features_speechiness',\n                                        'audio_features_acousticness',\n                                        'audio_features_instrumentalness',\n                                        'audio_features_liveness',\n                                        'audio_features_valence',\n                                        'audio_features_tempo'\n                                     ) \\\n                                  .distinct()\n\n# perform a merge operation on the data lake\noutput_songs_delta_table.alias(\"songs\").merge( \\\n    input_songs.alias(\"updates\"), \\\n    \"songs.artist_and_title = updates.artist_and_title\") \\\n  .whenMatchedUpdate(set = \n                     {   \n                        'track_id': 'updates.track_id',\n                        'track_href': 'updates.track_href',\n                        'track_is_local': 'updates.track_is_local',\n                        'track_is_playable': 'updates.track_is_playable',\n                        'track_name': 'updates.track_name',\n                        'track_popularity': 'updates.track_popularity',\n                        'track_track_number': 'updates.track_track_number',\n                        'track_type': 'updates.track_type',\n                        'track_uri': 'updates.track_uri',\n                        'track_duration_ms': 'updates.track_duration_ms',\n                        'track_disc_number': 'updates.track_disc_number',\n                        'track_explicit': 'updates.track_explicit',\n                        'track_external_ids_isrc': 'updates.track_external_ids_isrc',\n                        'album_album_type': 'updates.album_album_type',\n                        'album_href': 'updates.album_href',\n                        'album_id': 'updates.album_id',\n                        'album_name': 'updates.album_name',\n                        'album_release_date': 'updates.album_release_date',\n                        'album_release_date_precision': 'updates.album_release_date_precision',\n                        'album_total_tracks': 'updates.album_total_tracks',\n                        'album_type': 'updates.album_type',\n                        'album_uri': 'updates.album_uri',\n                        'album_album_type': 'updates.album_album_type',\n                        'is_track_downloaded': '1',\n                        'audio_features_danceability': 'updates.audio_features_danceability',\n                        'audio_features_energy': 'updates.audio_features_energy',\n                        'audio_features_key': 'updates.audio_features_key',\n                        'audio_features_loudness': 'updates.audio_features_loudness',\n                        'audio_features_mode': 'updates.audio_features_mode',\n                        'audio_features_speechiness': 'updates.audio_features_speechiness',\n                        'audio_features_acousticness': 'updates.audio_features_acousticness',\n                        'audio_features_instrumentalness': 'updates.audio_features_instrumentalness',\n                        'audio_features_liveness': 'updates.audio_features_liveness',\n                        'audio_features_valence': 'updates.audio_features_valence',\n                        'audio_features_tempo': 'updates.audio_features_tempo',\n                        'is_audio_features_downloaded': '1'\n                     } \n                    ) \\\n  .execute()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2848d524-5964-43fb-ac06-7ea9d396a97f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70b54758-7e2e-4ded-afeb-b43f89a18030"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"learn-sth-new-elt-2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2376466082312108}},"nbformat":4,"nbformat_minor":0}
